{"cells": [{"metadata": {}, "cell_type": "code", "source": "# Predicting House Prices in Australia\n# Import libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import ensemble\nfrom sklearn.metrics import mean_absolute_error", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Call created by inserting data file to code\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_67f476715e2f4a92b07bba55beba4ee6 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='cghZDWwzp8Q9Nk76wKTqIftpsT7g0RrEz14jzBR7bO58',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_67f476715e2f4a92b07bba55beba4ee6.get_object(Bucket='machinelearningforabsolutebeginne-donotdelete-pr-9hkcr7lauqnidf',Key='Melbourne_housing_FULL.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.head()", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "       Suburb             Address  Rooms Type      Price Method SellerG  \\\n0  Abbotsford       68 Studley St      2    h        NaN     SS  Jellis   \n1  Abbotsford        85 Turner St      2    h  1480000.0      S  Biggin   \n2  Abbotsford     25 Bloomburg St      2    h  1035000.0      S  Biggin   \n3  Abbotsford  18/659 Victoria St      3    u        NaN     VB  Rounds   \n4  Abbotsford        5 Charles St      3    h  1465000.0     SP  Biggin   \n\n        Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n0  3/09/2016       2.5    3067.0  ...       1.0  1.0     126.0           NaN   \n1  3/12/2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n2  4/02/2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n3  4/02/2016       2.5    3067.0  ...       2.0  1.0       0.0           NaN   \n4  4/03/2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n\n   YearBuilt         CouncilArea Lattitude  Longtitude             Regionname  \\\n0        NaN  Yarra City Council  -37.8014    144.9958  Northern Metropolitan   \n1        NaN  Yarra City Council  -37.7996    144.9984  Northern Metropolitan   \n2     1900.0  Yarra City Council  -37.8079    144.9934  Northern Metropolitan   \n3        NaN  Yarra City Council  -37.8114    145.0116  Northern Metropolitan   \n4     1900.0  Yarra City Council  -37.8093    144.9944  Northern Metropolitan   \n\n  Propertycount  \n0        4019.0  \n1        4019.0  \n2        4019.0  \n3        4019.0  \n4        4019.0  \n\n[5 rows x 21 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Suburb</th>\n      <th>Address</th>\n      <th>Rooms</th>\n      <th>Type</th>\n      <th>Price</th>\n      <th>Method</th>\n      <th>SellerG</th>\n      <th>Date</th>\n      <th>Distance</th>\n      <th>Postcode</th>\n      <th>...</th>\n      <th>Bathroom</th>\n      <th>Car</th>\n      <th>Landsize</th>\n      <th>BuildingArea</th>\n      <th>YearBuilt</th>\n      <th>CouncilArea</th>\n      <th>Lattitude</th>\n      <th>Longtitude</th>\n      <th>Regionname</th>\n      <th>Propertycount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abbotsford</td>\n      <td>68 Studley St</td>\n      <td>2</td>\n      <td>h</td>\n      <td>NaN</td>\n      <td>SS</td>\n      <td>Jellis</td>\n      <td>3/09/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>126.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yarra City Council</td>\n      <td>-37.8014</td>\n      <td>144.9958</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abbotsford</td>\n      <td>85 Turner St</td>\n      <td>2</td>\n      <td>h</td>\n      <td>1480000.0</td>\n      <td>S</td>\n      <td>Biggin</td>\n      <td>3/12/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>202.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yarra City Council</td>\n      <td>-37.7996</td>\n      <td>144.9984</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Abbotsford</td>\n      <td>25 Bloomburg St</td>\n      <td>2</td>\n      <td>h</td>\n      <td>1035000.0</td>\n      <td>S</td>\n      <td>Biggin</td>\n      <td>4/02/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>156.0</td>\n      <td>79.0</td>\n      <td>1900.0</td>\n      <td>Yarra City Council</td>\n      <td>-37.8079</td>\n      <td>144.9934</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Abbotsford</td>\n      <td>18/659 Victoria St</td>\n      <td>3</td>\n      <td>u</td>\n      <td>NaN</td>\n      <td>VB</td>\n      <td>Rounds</td>\n      <td>4/02/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yarra City Council</td>\n      <td>-37.8114</td>\n      <td>145.0116</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abbotsford</td>\n      <td>5 Charles St</td>\n      <td>3</td>\n      <td>h</td>\n      <td>1465000.0</td>\n      <td>SP</td>\n      <td>Biggin</td>\n      <td>4/03/2017</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>134.0</td>\n      <td>150.0</td>\n      <td>1900.0</td>\n      <td>Yarra City Council</td>\n      <td>-37.8093</td>\n      <td>144.9944</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 21 columns</p>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Learn more about the dataframe\ndf.shape\ndf.iloc[100]\ndf.columns", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n       'Longtitude', 'Regionname', 'Propertycount'],\n      dtype='object')"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Delete unneeded columns\ndel df['Address']\ndel df['Method']\ndel df['SellerG']\ndel df['Date']\ndel df['Postcode']\ndel df['Lattitude']\ndel df['Longtitude']\ndel df['Regionname']\ndel df['Propertycount']", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# View leftover columns\ndf.columns", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "Index(['Suburb', 'Rooms', 'Type', 'Price', 'Distance', 'Bedroom2', 'Bathroom',\n       'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea'],\n      dtype='object')"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Remove rows with any missing values, with no threshold on count of missing values, \n# with no subset of columns, and inplace (update, rather than replace) true\ndf.dropna(axis = 0, how ='any', thresh = None, subset = None, inplace = True)", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Count the number of rows in dataframe after deleting missing values\ndf.count", "execution_count": 8, "outputs": [{"output_type": "execute_result", "execution_count": 8, "data": {"text/plain": "<bound method DataFrame.count of            Suburb  Rooms Type      Price  Distance  Bedroom2  Bathroom  Car  \\\n2      Abbotsford      2    h  1035000.0       2.5       2.0       1.0  0.0   \n4      Abbotsford      3    h  1465000.0       2.5       3.0       2.0  0.0   \n6      Abbotsford      4    h  1600000.0       2.5       3.0       1.0  2.0   \n11     Abbotsford      3    h  1876000.0       2.5       4.0       2.0  0.0   \n14     Abbotsford      2    h  1636000.0       2.5       2.0       1.0  2.0   \n...           ...    ...  ...        ...       ...       ...       ...  ...   \n34847     Wollert      3    h   500000.0      25.5       3.0       2.0  2.0   \n34849     Wollert      3    h   570000.0      25.5       3.0       2.0  2.0   \n34853  Yarraville      2    h   888000.0       6.3       2.0       2.0  1.0   \n34854  Yarraville      2    t   705000.0       6.3       2.0       1.0  2.0   \n34856  Yarraville      2    h  1020000.0       6.3       2.0       1.0  0.0   \n\n       Landsize  BuildingArea  YearBuilt               CouncilArea  \n2         156.0          79.0     1900.0        Yarra City Council  \n4         134.0         150.0     1900.0        Yarra City Council  \n6         120.0         142.0     2014.0        Yarra City Council  \n11        245.0         210.0     1910.0        Yarra City Council  \n14        256.0         107.0     1890.0        Yarra City Council  \n...         ...           ...        ...                       ...  \n34847     383.0         118.0     2016.0   Whittlesea City Council  \n34849     404.0         158.0     2012.0   Whittlesea City Council  \n34853      98.0         104.0     2018.0  Maribyrnong City Council  \n34854     220.0         120.0     2000.0  Maribyrnong City Council  \n34856     250.0         103.0     1930.0  Maribyrnong City Council  \n\n[8895 rows x 12 columns]>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# For non-numeric columns, determine how many unique values there are before one-hot encoding\n# One-hot encoding is replacing categorical variables with dummy binary variables before building\n# machine-learning model\ndf['Suburb'].nunique()\ndf['Type'].nunique()\ndf['CouncilArea'].nunique()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# See the datatype for each dataframe column\ndf.dtypes\n# Suburb, CouncilArea and Type columns return object for string. One-hot encode these columns\n# Other columns are int or float\ndf = pd.get_dummies(df,columns = ['Suburb','CouncilArea','Type'])", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.dtypes\n# Assign independent variables to X, and dependent variables to y with Price\nX = df.drop('Price',axis=1)\ny = df['Price']", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Shuffle and split the dataset to train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,shuffle=True)", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Select model algorithm and configure hyperparameters\nmodel = ensemble.GradientBoostingRegressor(\nn_estimators = 150,\nlearning_rate = 0.1,\nmax_depth = 30,\nmin_samples_split = 4,\nmin_samples_leaf = 6,\nmax_features = 0.6,\nloss = 'huber'\n)", "execution_count": 30, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Fit model to training set\nmodel.fit(X_train,y_train)", "execution_count": 31, "outputs": [{"output_type": "execute_result", "execution_count": 31, "data": {"text/plain": "GradientBoostingRegressor(loss='huber', max_depth=30, max_features=0.6,\n                          min_samples_leaf=6, min_samples_split=4,\n                          n_estimators=150)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Determine training set MAE. On average, how much has price being miscalculated in the training set?\nmae_train = mean_absolute_error(y_train, model.predict(X_train))\nprint(\"Training Set Mean Absolute Error: %.2f\"% mae_train)", "execution_count": 34, "outputs": [{"output_type": "stream", "text": "Training Set Mean Absolute Error: 28636.48\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Determine test set MAE. On average, how much has price being miscalculated in the test set?\nmae_test = mean_absolute_error(y_test, model.predict(X_test))\nprint(\"Test Set Mean Absolute Error: %.2f\"% mae_test)", "execution_count": 35, "outputs": [{"output_type": "stream", "text": "Test Set Mean Absolute Error: 171669.51\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Low training set MAE and high test set MAE means that our models are overfitted and \n# we must now optimize the model", "execution_count": 36, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# MODEL OPTIMIZATION\n# 1. Adjust maximum depth hyperparameter in model.Change from 30 to 5\nmodel2 = ensemble.GradientBoostingRegressor(\nn_estimators = 150,\nlearning_rate = 0.1,\nmax_depth = 5,\nmin_samples_split = 4,\nmin_samples_leaf = 6,\nmax_features = 0.6,\nloss = 'huber'\n)\nmodel2.fit(X_train,y_train)\nmae2_train = mean_absolute_error(y_train, model2.predict(X_train))\nmae2_test = mean_absolute_error(y_test, model2.predict(X_test))", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(mae2_train)\nprint(mae2_test)", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "135562.4660685072\n163748.8041647579\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# 2. Adjust n_estimators hyperparameter in model.Change from 150 to 250\nmodel3 = ensemble.GradientBoostingRegressor(\nn_estimators = 250,\nlearning_rate = 0.1,\nmax_depth = 5,\nmin_samples_split = 4,\nmin_samples_leaf = 6,\nmax_features = 0.6,\nloss = 'huber'\n)\nmodel3.fit(X_train,y_train)\nmae3_train = mean_absolute_error(y_train, model3.predict(X_train))\nmae3_test = mean_absolute_error(y_test, model3.predict(X_test))", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(mae3_train)\nprint(mae3_test)", "execution_count": 23, "outputs": [{"output_type": "stream", "text": "123861.00665119664\n158123.1239655676\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# 3. Try grid search\nmodel4 = ensemble.GradientBoostingRegressor()\nhyperparameters = {\n    'n_estimators': [200,300],\n    'learning_rate': [0.01,0.02],\n    'max_depth': [4,6],\n    'min_samples_split': [3,4],\n    'min_samples_leaf': [5,6],\n    'max_features': [0.8,0.9],\n    'loss': ['ls','lad','huber']\n}\n# Defne grid search & run with 4 CPUs in parallel\nfrom sklearn.model_selection import GridSearchCV\ngrid = GridSearchCV(model4,hyperparameters,n_jobs=4)", "execution_count": 27, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Run grid search on training data\ngrid.fit(X_train,y_train)\n# Return optimal hyperparameters\ngrid.best_params_\n# Check model accuracy with determined optimal hyperparameters\nmae4_train = mean_absolute_error(y_train,grid.predict(X_train))\nmae4_test = mean_absolute_error(y_test,grid.predict(X_test))", "execution_count": 28, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(mae4_train)\nprint(mae4_test)", "execution_count": 29, "outputs": [{"output_type": "stream", "text": "141147.2308050096\n173506.3952639447\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Even after doing a grid search for a Gradient Boosting Regressor's optimal\n# hyperparameters, the mae's are still pretty high", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}